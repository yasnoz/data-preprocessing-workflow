{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Workflow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üéØ This exercise will guide you through the preprocessing workflow. Step by step, feature by feature, you will investigate the dataset and take preprocessing decisions accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üå§ We stored the `ML_Houses_dataset.csv` [here](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Houses_dataset.csv) in the cloud.\n",
    "\n",
    "üëá Run the code down below to load the dataset and features you will be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Loading the dataset\n",
    "url = \"https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Houses_dataset.csv\"\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Selecting some columns of interest\n",
    "selected_features = ['GrLivArea',\n",
    "                     'BedroomAbvGr',\n",
    "                     'KitchenAbvGr', \n",
    "                     'OverallCond',\n",
    "                     'RoofSurface',\n",
    "                     'GarageFinish',\n",
    "                     'CentralAir',\n",
    "                     'ChimneyStyle',\n",
    "                     'MoSold',\n",
    "                     'SalePrice']\n",
    "\n",
    "# Overwriting the \"data\" variable to keep only the columns of interest\n",
    "# Notice the .copy() to copy the values \n",
    "data = data[selected_features].copy()\n",
    "\n",
    "# Showing the first five rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üìö Take the time to do a ***preliminary investigation*** of the features by reading the ***dataset description*** available [here](https://wagon-public-datasets.s3.amazonaws.com/Machine%20Learning%20Datasets/ML_Houses_dataset_description.txt). Make sure to refer to it throughout the day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) Duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ÑπÔ∏è ***Duplicates in datasets cause data leakage.*** \n",
    "\n",
    "üëâ It is important to locate and remove duplicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì How many duplicated rows are there in the dataset ‚ùì\n",
    "\n",
    "<i>Save your answer under variable name `duplicate_count`.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Remove the duplicates from the dataset. Overwite the dataframe `data`‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('duplicates',\n",
    "                         duplicates = duplicate_count,\n",
    "                         dataset = data\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì Print the percentage of missing values for every column of the dataframe. ‚ùì"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GarageFinish`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** about `GarageFinish` ‚ùì\n",
    "\n",
    "Investigate the missing values in `GarageFinish`. Then, choose one of the following solutions:\n",
    "\n",
    "1. Drop the column entirely\n",
    "2. Impute the column median using `SimpleImputer` from Scikit-Learn\n",
    "3. Preserve the NaNs and replace them with meaningful values\n",
    "\n",
    "Make changes effective in the dataframe `data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è According to the dataset description, the missing values in `GarageFinish` represent a house having no garage. They need to be encoded as such.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RoofSurface`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** about `RoofSurface` ‚ùì\n",
    "\n",
    "Investigate the missing values in `RoofSurface`. Then, choose one of the following solutions:\n",
    "\n",
    "1. Drop the column entirely\n",
    "2. Impute the column median using sklearn's `SimpleImputer`\n",
    "3. Preserve the NaNs and replace them with meaningful values\n",
    "\n",
    "Make changes effective in the dataframe `data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è `RoofSurface` has a few missing values that can be imputed by the median value.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `ChimneyStyle`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** about `ChimneyStyle` ‚ùì\n",
    "\n",
    "Investigate the missing values in `ChimneyStyle`. Then, choose one of the following solutions:\n",
    "\n",
    "1. Drop the column entirely\n",
    "2. Impute the column median\n",
    "3. Preserve the NaNs and replace them with meaningful values\n",
    "\n",
    "Make changes effective in the dataframe `data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "* ‚ö†Ô∏è Be careful: not all missing values are represented as `np.nans`, and Python's `isnull()` only detects `np.nans`...\n",
    "    \n",
    "* ‚ÑπÔ∏è `ChimneyStyle` has a lot of missing values. The description does not touch on what they represent. As such, it is better not to make any assumptions and to drop the column entirely.\n",
    "    \n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('missing_values',\n",
    "                         dataset = data\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì When you are done with handling missing value, print out the percentage of missing values for the entire dataframe ‚ùì\n",
    "\n",
    "You should no longer have missing values !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (3) Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First of all, before scaling...**\n",
    "\n",
    "To understand the effects of scaling and encoding on model performance, let's get a **base score without any data transformation**.\n",
    "\n",
    "‚ùì Cross-validate a linear regression model that predicts `SalePrice` using the other features ‚ùì\n",
    "\n",
    "‚ö†Ô∏è Note that a linear regression model can only handle numeric features. [DataFrame.select_dtypes](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.select_dtypes.html) can help."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep this score in mind! You will train a new model after data preprocessing in Challenge #2 - see if it improves your average score üòâ\n",
    "\n",
    "üöÄ Now, back to **feature scaling**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  `RoofSurface` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `RoofSurface` ‚ùì\n",
    "\n",
    "üëá Investigate `RoofSurface` for distribution and outliers. Then, choose the most appropriate scaling technique. Either:\n",
    "\n",
    "1. Standard Scaler\n",
    "2. Robust Scaler\n",
    "3. MinMax Scaler\n",
    "\n",
    "Replace the original columns with the transformed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è Since `RoofSurface` has neither a Gaussian distribution, nor outliers $\\rightarrow$ MinMaxScaler.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GrLivArea`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `GrLivArea` ‚ùì\n",
    "\n",
    "üëá Investigate `GrLivArea` for distribution and outliers. Then, choose the most appropriate scaling technique. Either:\n",
    "\n",
    "1. Standard Scaler\n",
    "2. Robust Scaler\n",
    "3. MinMax Scaler\n",
    "\n",
    "Replace the original columns with the transformed values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è `GrLivArea` has many outliers $\\rightarrow$ RobustScaler()\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `BedroomAbvGr` ,  `OverallCond` & `KitchenAbvGr`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Questions** about `BedroomAbvGr`, `OverallCond` & `KitchenAbvGr` ‚ùì\n",
    "\n",
    "üëá Investigate `BedroomAbvGr`, `OverallCond` & `KitchenAbvGr`. Then, chose one of the following scaling techniques:\n",
    "\n",
    "1. MinMax Scaler\n",
    "2. Standard Scaler\n",
    "3. Robust Scaler\n",
    "\n",
    "Replace the original columns with the transformed values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è `BedroomAbvGr` ,  `OverallCond` & `KitchenAbvGr` are ordinal features. There are less than 0.1% of outliers so no need to use _RobustScaler()_. The distribution is not Gaussian, hence no _StandardScaler()_. By elimination, you can confidently choose _MinMaxScaler()_.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('scaling',\n",
    "                         dataset = data\n",
    ")\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (4) Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `GarageFinish`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `GarageFinish`‚ùì\n",
    "\n",
    "üëá Investigate `GarageFinish` and choose one of the following encoding techniques accordingly:\n",
    "- Ordinal encoding\n",
    "- One-Hot encoding\n",
    "\n",
    "Add the encoding to the dataframe as new colum(s), and remove the original column.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "        \n",
    "‚ÑπÔ∏è `GarageFinish` is a multicategorical feature that should be One-hot-encoded. You could also consider an Ordinal Encoding but we would have to know for sure that Unfinished or no garage are definitely worse that rough finished!\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GarageFinish_ohe.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding  `CentralAir`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `CentralAir`‚ùì\n",
    "\n",
    "Investigate `CentralAir` and choose one of the following encoding techniques accordingly:\n",
    "- Ordinal encoding\n",
    "- One-Hot encoding\n",
    "\n",
    "Replace the original column with the newly generated encoded columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "‚ÑπÔ∏è `CentralAir` is a binary categorical feature.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (5) Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `MoSold` - Cyclical engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë®üèª‚Äçüè´ A feature can be numerical (continuous or discrete), categorical or ordinal. But a feature can also be temporal (e.g. quarters, months, days, minutes, ...). \n",
    "\n",
    "Cyclical features like time need some specific preprocessing. Indeed, if you want any Machine Learning algorithm to capture this cyclicity, your cyclical features must be preprocessed in a certain way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëâ Consider the feature `MoSold`, the month on which the house was sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"MoSold\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Many houses were sold in June (6), July (7) and May (5) (Spring/Summer)\n",
    "* Only a few houses were sold in December (12), January (1) and February (2) (~ Fall/Winter)\n",
    "    * But for any Machine Learning model, there is no reason why December (12) and January (1) would be \"close\"..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üë©üèª‚Äçüè´ ***How to deal with cyclical features?***\n",
    "\n",
    "1.  Look at the following illustration and read the explanations to distinguish two different months.\n",
    "\n",
    "<img src=\"https://wagon-public-datasets.s3.amazonaws.com/05-Machine-Learning/02-Prepare-the-dataset/cyclical_feature_engineering.png\" alt=\"Cyclical features\" width=\"1000\">\n",
    "\n",
    "\n",
    "2. Read this [article](https://ianlondon.github.io/posts/encoding-cyclical-features-24-hour-time/) for more details.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ùì **Question** about `MoSold` ‚ùì \n",
    "- Create two new features `sin_MoSold` and `cos_MoSold` which correspond respectively to the sine and cosine of MoSold.\n",
    "- Drop the original column `MoSold`\n",
    "\n",
    "<details>\n",
    "    <summary>üí° <i>Hint</i></summary>\n",
    "    \n",
    "To create a time engineered feature based on a column which gives the second in the day!\n",
    "```python\n",
    "seconds_in_day = 24*60*60\n",
    "\n",
    "df['sin_time'] = np.sin(2*np.pi*df.seconds/seconds_in_day)\n",
    "df['cos_time'] = np.cos(2*np.pi*df.seconds/seconds_in_day)\n",
    "df.drop(columns=['seconds'], inplace=True)\n",
    "\n",
    "df.head()\n",
    "```\n",
    "\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üß™ **Test your code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbresult import ChallengeResult\n",
    "\n",
    "result = ChallengeResult('encoding', dataset = data, new_features = ['sin_MoSold', 'cos_MoSold'])\n",
    "\n",
    "result.write()\n",
    "print(result.check())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (6) Export the preprocessed dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üëá Now that the dataset has been preprocessed, execute the code below to export it. You will keep working on it in the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/clean_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üèÅ Congratulations! Now, you know how to ***preprocess a dataset*** !\n",
    "\n",
    "üíæ Don't forget to git add/commit/push your notebook...\n",
    "\n",
    "üöÄ ... and move on to the next challenge!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
